(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{435:function(t,e,a){t.exports=a.p+"assets/img/ukds-pipeline-flow.8cf26465.png"},436:function(t,e,a){t.exports=a.p+"assets/img/ukds-au-pairing-datasheet.6d159749.png"},437:function(t,e,a){t.exports=a.p+"assets/img/ukds-govt-petitions-datasheet.d9d1cb8a.png"},579:function(t,e,a){"use strict";a.r(e);var s=a(29),n=Object(s.a)({},(function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("p",[t._v("The UK Data Service, like many other research repository services, employs a range of closed source software solutions for the publication and consumption of research data. The data itself is often published in closed and proprietary data formats, and the data is not always, or purposefully, published in a way that enables data reuse.")]),t._v(" "),s("p",[t._v("Based on an initial exploration of user need, we identified, together with the UK Data Service, the following areas for a Frictionless Data pilot:")]),t._v(" "),s("ul",[s("li",[t._v("Conversion of data and metadata to open formats using open source tools.")]),t._v(" "),s("li",[t._v("Use the Frictionless Data toolchain to assess and report on data quality (as a proxy for reusability).")]),t._v(" "),s("li",[t._v("Demonstrate the possibility of generating visualizations from source data and metadata, described with Frictionless Data specifications.")]),t._v(" "),s("li",[t._v("Host the data with all these attributes (open formats, reusable quality, visualized) on an open source platform for data.")])]),t._v(" "),s("p",[t._v("We worked with data that was publicly accessible, and therefore in its post-publication phase. This also informed the way we designed the work, as a set of connected processing and transport steps, very much outside of the publication process itself. While this was acceptable for the scope of the pilot, the real power of the approach we demonstrate here is in integrating it with pre-publication phases of data, via a combined automated and manually curated data process. Indeed, we can see via this pilot the potential to streamline the workflow demonstrated into a complete research data publication process, and would welcome the opportunity to conduct one or more pilots that build on this approach, deeply integrated into pre-publication data workflows.")]),t._v(" "),s("h2",{attrs:{id:"context"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#context"}},[t._v("#")]),t._v(" Context")]),t._v(" "),s("p",[t._v("The UK Data Service offers an online repository where researchers can archive, publish and share research data, called "),s("a",{attrs:{href:"http://reshare.ukdataservice.ac.uk/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Reshare"),s("OutboundLink")],1),t._v(". Reshare exposes an "),s("a",{attrs:{href:"https://www.openarchives.org/pmh/",target:"_blank",rel:"noopener noreferrer"}},[t._v("OAI-PMH"),s("OutboundLink")],1),t._v(" endpoint to facilitate metadata harvesting.")]),t._v(" "),s("p",[s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(" is a data workflows web application build around the modular Frictionless Data toolchain, designed to find, share and publish high quality data online. Each entry has a ‘Showcase’ to display data package properties, and preview data with tables and simple visualisations. As well as the Showcase, "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(" provides straight-forward direct access to import data into a variety of tools used by researchers; R, Pandas, Python, JavaScript, and SQL. "),s("a",{attrs:{href:"https://specs.frictionlessdata.io/data-package/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Frictionless Data Data Packages"),s("OutboundLink")],1),t._v(" can be pushed to "),s("a",{attrs:{href:"http://datahub.io",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(" to create dataset entries.")]),t._v(" "),s("h3",{attrs:{id:"problem-we-were-trying-to-solve"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#problem-we-were-trying-to-solve"}},[t._v("#")]),t._v(" Problem We Were Trying To Solve")]),t._v(" "),s("p",[t._v("We want to investigate the use of the Data Package concept, and Frictionless Data software to facilitate the reuse of data archived in Reshare.")]),t._v(" "),s("p",[t._v("We are especially interested in trialling pipelines to automate data harvesting from UKDS into "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(" using Frictionless Data software such as "),s("a",{attrs:{href:"https://github.com/frictionlessdata/datapackage-pipelines",target:"_blank",rel:"noopener noreferrer"}},[t._v("datapackage-pipelines"),s("OutboundLink")],1),t._v(", and creating appropriate processors to translate widely used statistics file formats, such as "),s("a",{attrs:{href:"https://www.ibm.com/analytics/us/en/technology/spss/",target:"_blank",rel:"noopener noreferrer"}},[t._v("SPSS"),s("OutboundLink")],1),t._v(", to text-based tabular data formats such as CSV.")]),t._v(" "),s("p",[t._v("We chose the Data Package Pipelines library because it provides us with a well tested and mature framework of established processors to work with tabular data from a variety of sources and formats. Custom processors can easily be added to extend pipeline functionality. Pipelines can be configured using a simple declarative specification. Other tools supporting the underlying Frictionless Data specifications, such as "),s("a",{attrs:{href:"https://github.com/frictionlessdata/tableschema-py/",target:"_blank",rel:"noopener noreferrer"}},[t._v("tableschema"),s("OutboundLink")],1),t._v(" and "),s("a",{attrs:{href:"https://github.com/frictionlessdata/tableschema-py/",target:"_blank",rel:"noopener noreferrer"}},[t._v("goodtables"),s("OutboundLink")],1),t._v(" can be easily integrated as appropriate.")]),t._v(" "),s("p",[t._v("In this pilot we are trialling tools to:")]),t._v(" "),s("ul",[s("li",[t._v("automate data harvesting from UKDS, to "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(", through a data package pipeline.")]),t._v(" "),s("li",[t._v("translate binary data formats (SPSS) to text-based tabular formats.")]),t._v(" "),s("li",[t._v("validate tabular data harvested from UKDS with goodtables.")]),t._v(" "),s("li",[t._v("fix or workaround common data issues identified from validation report, in the source-spec")]),t._v(" "),s("li",[t._v("correct file encoding")]),t._v(" "),s("li",[t._v("skip non-data rows")]),t._v(" "),s("li",[t._v("skip specified validation checks (duplicate-rows)")]),t._v(" "),s("li",[t._v("specify header rows in csv files")]),t._v(" "),s("li",[t._v("explicitly defining tabular headers")]),t._v(" "),s("li",[t._v("trial the "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(" API with real-world data")]),t._v(" "),s("li",[t._v("use the Showcase features of "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(" to provide instance data previews and visualisations.")])]),t._v(" "),s("h3",{attrs:{id:"the-work"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#the-work"}},[t._v("#")]),t._v(" The Work")]),t._v(" "),s("h4",{attrs:{id:"what-did-we-do"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#what-did-we-do"}},[t._v("#")]),t._v(" What Did We Do")]),t._v(" "),s("p",[t._v("During the pilot, we focussed on creating a reusable pipeline of processors to harvest data and dataset metadata from the UKDS Reshare service, and output valid Data Packages with tabular resources. Each pipeline processor step was created as a separate module to facilitate testing and reuse in other similar pipelines.")]),t._v(" "),s("p",[t._v("UKDS datasets were selected from "),s("a",{attrs:{href:"http://reshare.ukdataservice.ac.uk/cgi/stats/report/most_popular_eprints",target:"_blank",rel:"noopener noreferrer"}},[t._v("the UKDS list"),s("OutboundLink")],1),t._v(". Entries were selected based on the data format we intended to write processors for (.csv, .tsv, xls, or .sav), how the dataset might help demonstrate various aspects of the pipeline, and how well they might lend themselves to visualisation on "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("p",[t._v("Below is an outline of the pipeline flow from UKDS Reshare Archive to "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(" entry:")]),t._v(" "),s("p",[s("img",{attrs:{src:a(435),alt:"pipeline flow from UKDS Reshare Archive to datahub.io"}}),s("br"),t._v(" "),s("em",[t._v("pipeline flow from UKDS Reshare Archive to "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1)])]),t._v(" "),s("h5",{attrs:{id:"specifying-an-entry"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#specifying-an-entry"}},[t._v("#")]),t._v(" Specifying an Entry")]),t._v(" "),s("p",[t._v("We wanted to ensure that each UKDS dataset to be maintained on "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(" could be easily configured to specify where to harvest its resource data and dataset metadata. We also wanted to add other configuration details to help customise the pipeline to work with tricky resources, and view specifications for subsequent visualisation on "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("p",[t._v("The source-spec for each Reshare entry defines a list of URLs for each resource in the dataset that we’re interested in harvesting, and the resource format (csv, tsv, xls, or spss).")]),t._v(" "),s("p",[t._v("If an OAI ID is provided, it will be used to harvest dataset metadata from the Reshare OAI endpoint.")]),t._v(" "),s("p",[t._v("As well as defining source locations, we also want to provide a way to customise downstream processor behaviour, to help work around potential resource issues.")]),t._v(" "),s("p",[t._v("Below is an example yaml source-spec for two entries, demonstrating various configuration options.")]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("entries")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n  "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("civil-servant-survey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# entry name")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("source")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# a list of sources")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("url")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" http"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//reshare.ukdataservice.ac.uk/851401/10/Coded_SurveyData.csv\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" csv\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("url")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" http"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//reshare.ukdataservice.ac.uk/851401/2/key%20%283%29.csv\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" csv\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("goodtables")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("           "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# custom processor config for goodtables")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("skip_checks")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" duplicate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("row\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("oai-id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("851401")]),t._v("        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# OAI ID to harvest dataset metadata")]),t._v("\n\n  "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("uk-gov-petitions")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("source")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("url")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" http"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//reshare.ukdataservice.ac.uk/851614/1/gov_pet_metadata.tab\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tsv\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tabulator")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# custom processor config for tabulator")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("encoding")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" utf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# explicitly define source file encoding")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("headers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# explicitly define missing column headers")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" id\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" title\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" department\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" starting\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" closing\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("oai-id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("851614")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("views")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" views/petitions"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("view.json\n")])])]),s("p",[t._v("Sources in the first entry, "),s("em",[t._v("civil-servant-survey")]),t._v(", contain duplicate rows, which would normally fail goodtables validation. Here we will allow the "),s("code",[t._v("duplicate-row")]),t._v(" check to be skipped.")]),t._v(" "),s("p",[t._v("The source in the second entry has the wrong character encoding and no headers declared. We can fix these issues to allow the pipeline to process the resource by explicitly specifying the file encoding, and declaring the column headers.")]),t._v(" "),s("h4",{attrs:{id:"data-set-and-resource-harvest"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#data-set-and-resource-harvest"}},[t._v("#")]),t._v(" Data Set and Resource Harvest")]),t._v(" "),s("p",[t._v("We identified that Reshare has an OAI-PMH2 compatible endpoint to harvest information about each Reshare data set. So we created an "),s("code",[t._v("ukds.add_oai_metadata")]),t._v(" pipeline processor. OAI metadata is compatible with Dublin Core Elements, and the processor translates this into Data Package compatible properties.")]),t._v(" "),s("p",[t._v("Resources are added to the newly created Data Package and downloaded from the URLs defined in the yaml configuration. We support adding SPSS (.sav), CSV, TSV and XLS file formats.")]),t._v(" "),s("p",[t._v("To support the widely used SPSS format, we created an "),s("code",[t._v("spss.add_spss processor")]),t._v(" that makes use of the "),s("a",{attrs:{href:"https://github.com/frictionlessdata/tableschema-spss-py",target:"_blank",rel:"noopener noreferrer"}},[t._v("tableschema-spss"),s("OutboundLink")],1),t._v(" plugin to read SPSS files and create tableschema descriptors from them.")]),t._v(" "),s("h4",{attrs:{id:"validation-reports-and-common-issues"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#validation-reports-and-common-issues"}},[t._v("#")]),t._v(" Validation Reports and Common Issues")]),t._v(" "),s("p",[t._v("To help ensure data quality, we want to validate the harvested tabular data before continuing the pipeline. We created a "),s("a",{attrs:{href:"https://github.com/frictionlessdata/datapackage-pipelines-goodtables",target:"_blank",rel:"noopener noreferrer"}},[s("code",[t._v("goodtables.validate")]),t._v(" processor"),s("OutboundLink")],1),t._v(", which will write a validation report for each resource. If a resource fails to validate against its schema, or has other data issues, the pipeline will fail. Errors can be identified from validation reports, fixed, and the pipeline re-run.")]),t._v(" "),s("p",[t._v("Below are examples of  issues revealed by validation that can occur when working with real-world data.")]),t._v(" "),s("h5",{attrs:{id:"au-pairing-after-the-au-pair-scheme-specifying-a-xls-sheet-and-working-around-non-data-rows"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#au-pairing-after-the-au-pair-scheme-specifying-a-xls-sheet-and-working-around-non-data-rows"}},[t._v("#")]),t._v(" “Au pairing after the au pair scheme”: specifying a xls sheet, and working around non-data rows")]),t._v(" "),s("p",[t._v("The "),s("a",{attrs:{href:"http://reshare.ukdataservice.ac.uk/851656/",target:"_blank",rel:"noopener noreferrer"}},[t._v("“Au Pairing” dataset"),s("OutboundLink")],1),t._v(" has a single .xls resource we’re interested in harvesting. The file contains four sheets, and we’re interested in the second one, which contains the data. So we specify our entry:")]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("au-pairing")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("source")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("url")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" http"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//reshare.ukdataservice.ac.uk/851656/6/GumtreeAds_AuPairsAnalysis1.xls\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" xls\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tabulator")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sheet")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# use sheet 2 in the file")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("oai-id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("851656")]),t._v("\n")])])]),s("p",[t._v("Notice we have indicated which sheet in the file to use.")]),t._v(" "),s("p",[t._v("The data sheet has a single header row, but it also has this header row repeated at intervals throughout the data, presumably to aid the human reader when reviewing the data manually.")]),t._v(" "),s("p",[s("img",{attrs:{src:a(436),alt:""}}),s("br"),t._v(" "),s("em",[t._v("screengrab of the UKDS “Au Pairing” datasheet")])]),t._v(" "),s("p",[t._v("For machine processing, this isn’t ideal. In fact, it will fail our goodtables validation processor with the following (truncated) report:")]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v('"time"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.466")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v('"valid"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v('"error-count"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("13")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v('"table-count"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v('"tables"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("...")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v('"errors"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v('"code"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"duplicate-row"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v('"message"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Row 347 is duplicated to row(s) 236"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v('"row-number"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("347")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v('"column-number"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token null important"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v('"row"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n                        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"happy/energetic/caring/loving outlook required"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"CV requested"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"gender specified"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cooking"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("...")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("...")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("...")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("You can find the full report "),s("a",{attrs:{href:"https://gist.github.com/brew/8401e2875ec6d829baf95b79cd677e28",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("p",[t._v("The report tells us there are 13 errors, and lists where they are. In this case they indicate that duplicate rows are present (the repeated header). This can either be fixed within Reshare, or we can add a parameter to our entry specification to skip each row that contains the duplicate header:")]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("au-pairing")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("source")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("url")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" http"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//reshare.ukdataservice.ac.uk/851656/6/GumtreeAds_AuPairsAnalysis1.xls\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" xls\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tabulator")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sheet")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("skip_rows")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("237")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("292")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("348")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("402")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("458")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("511")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("564")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("618")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("673")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("726")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("779")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("832")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("886")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("937")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("990")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("goodtables")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("skip_checks")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" duplicate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("row\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("oai-id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("851656")]),t._v("\n")])])]),s("p",[t._v("Above we’ve added a "),s("code",[t._v("skip_rows")]),t._v(" parameter with a list of row numbers to skip when generating the data package. We also instruct goodtables to skip the "),s("code",[t._v("duplicate-row")]),t._v(" check."),s("br"),t._v("\nThe outputted csv resource file will no longer contain rows with the duplicate header.")]),t._v(" "),s("h5",{attrs:{id:"uk-government-petitions-wrong-file-encoding-and-specifying-missing-headers"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#uk-government-petitions-wrong-file-encoding-and-specifying-missing-headers"}},[t._v("#")]),t._v(" “UK government petitions”: wrong file encoding, and specifying missing headers")]),t._v(" "),s("p",[t._v("The “"),s("a",{attrs:{href:"http://gov.uk/",target:"_blank",rel:"noopener noreferrer"}},[t._v("gov.uk"),s("OutboundLink")],1),t._v(" petitions” dataset has a TSV data file we’re interested in. However, it has been saved with the wrong character encoding and attempting to open may return an error, or display some characters incorrectly.")]),t._v(" "),s("p",[t._v("Additionally, there is no header row specified at the top of the file, so the resulting data package won’t have the correct header information in the resource’s schema.")]),t._v(" "),s("p",[t._v("We can fix both of these issues in our entry specification:")]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("uk-gov-petitions")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("source")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("url")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" http"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//reshare.ukdataservice.ac.uk/851614/1/gov_pet_metadata.tab\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tsv\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tabulator")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("encoding")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" utf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# specify file encoding")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("headers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# define missing headers")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" id\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" title\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" department\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" starting\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" closing\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("oai-id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("851614")]),t._v("\n")])])]),s("p",[t._v("Above, we have defined the character encoding we want to use when opening the file, and we’ve explicitly defined the headers to use. These headers will be added to the first row of the outputted csv resource file in the data package.")]),t._v(" "),s("p",[t._v("We can also use the "),s("code",[t._v("headers")]),t._v(" parameter to define which row contains header information. By default this is the first row. However, sometimes a data file will have the headers on a different row:")]),t._v(" "),s("p",[s("img",{attrs:{src:a(437),alt:""}}),s("br"),t._v(" "),s("em",[t._v("screengrab of the UKDS “Government Petitions” datasheet")])]),t._v(" "),s("p",[t._v("This example file has its headers defined in row three, with other information, and an empty row in the first two rows. We can tell our pipeline which row contains headers by specifying it in the entry configuration:")]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("example-entry")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("source")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("url")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" http"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//www.newcastle.gov.uk/sites/drupalncc.newcastle.gov.uk/files/wwwfileroot/your"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("council/local_transparency/january_2012.csv\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" csv\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tabulator")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("headers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# specifying which row contains headers")]),t._v("\n")])])]),s("h4",{attrs:{id:"add-data-package-views"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#add-data-package-views"}},[t._v("#")]),t._v(" Add Data Package Views")]),t._v(" "),s("p",[t._v("View specs can be added to the data package to enable "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(" to create visualisations from resource data in the data package. The "),s("code",[t._v("views")]),t._v(" property is a list of file paths to json files containing "),s("a",{attrs:{href:"https://specs.frictionlessdata.io/views/",target:"_blank",rel:"noopener noreferrer"}},[t._v("view-spec"),s("OutboundLink")],1),t._v(" compatible views.")]),t._v(" "),s("p",[t._v("Currently, "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(" supports views written either with a ‘simple’ views-spec, or using Vega (v 2.6.5). See "),s("a",{attrs:{href:"https://datahub.io/docs/features/views",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io docs"),s("OutboundLink")],1),t._v(" for more details about the supported views-spec.")]),t._v(" "),s("h4",{attrs:{id:"push-to-datahub-io"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#push-to-datahub-io"}},[t._v("#")]),t._v(" Push to "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1)]),t._v(" "),s("p",[t._v("Once the harvesting pipeline has been run the resulting data packages are pushed to "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(" using the "),s("a",{attrs:{href:"https://github.com/datahq/datahub-cli",target:"_blank",rel:"noopener noreferrer"}},[s("code",[t._v("datahub.dump.to_datahub")]),s("OutboundLink")],1),t._v(" processor.")]),t._v(" "),s("p",[t._v("This creates or updates an entry for the package on datahub. If a view has been defined in the entry configuration, this will be created on the "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(" entry Showcase page.")]),t._v(" "),s("h3",{attrs:{id:"review"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#review"}},[t._v("#")]),t._v(" Review")]),t._v(" "),s("p",[t._v("We were able to demonstrate that a data processing pipeline using Frictionless Data tools can facilitate the automated harvesting, validation, transformation, and upload to a data package-compatible third-party service, based on a simple configuration.")]),t._v(" "),s("h3",{attrs:{id:"next-steps"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#next-steps"}},[t._v("#")]),t._v(" Next Steps")]),t._v(" "),s("p",[t._v("The pilot data package pipeline runs locally in a development environment, but given each processor has been written as a separate module, these could be used within any pipeline. "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(" uses datapackage-pipelines within its infrastructure, and the processors developed for this project could be used within "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(" itself to facilitate the automatic harvesting of datasets from OAI-PMH enabled data sources.")]),t._v(" "),s("p",[t._v("Once a pipeline is in place, it can be scheduled to run each day (or week, month, etc.). This would ensure "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(" is up-to-date with data on UKDS Reshare.")]),t._v(" "),s("p",[t._v("Working with ‘real-world’ data from UKDS Reshare has helped to identify and prioritise improvements and future features for "),s("a",{attrs:{href:"http://datahub.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("h3",{attrs:{id:"additional-resources"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#additional-resources"}},[t._v("#")]),t._v(" Additional Resources")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"https://github.com/frictionlessdata/pilot-ukds",target:"_blank",rel:"noopener noreferrer"}},[t._v("The main code repository for this pilot"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("li",[s("a",{attrs:{href:"https://github.com/frictionlessdata/datapackage-pipelines",target:"_blank",rel:"noopener noreferrer"}},[t._v("A framework for processing data packages in pipelines of modular components"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("li",[s("a",{attrs:{href:"https://github.com/frictionlessdata/datapackage-pipelines-spss",target:"_blank",rel:"noopener noreferrer"}},[t._v("A Data Package Pipelines processor for SPSS file formats"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("li",[s("a",{attrs:{href:"https://github.com/frictionlessdata/datapackage-pipelines-goodtables",target:"_blank",rel:"noopener noreferrer"}},[t._v("A Data Package Pipelines processor for validating tabular data using goodtables-py"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("li",[s("a",{attrs:{href:"https://github.com/datahq/datapackage-pipelines-datahub",target:"_blank",rel:"noopener noreferrer"}},[t._v("A Data Package Pipelines processor to push data packages to datahub.io"),s("OutboundLink")],1),t._v(".")])])])}),[],!1,null,null,null);e.default=n.exports}}]);